{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw07.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZXw_9moBiZm",
        "outputId": "eddc2c60-1c31-4f6d-9ced-fd8db8d68233"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 34 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.3\n",
            "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 49.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=f8efb68edb97161555d26abbaad9b122ff28216554a60564367003001be79812\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "\n",
        "spark = pyspark.sql.SparkSession.builder.getOrCreate()\n",
        "sc = spark.sparkContext\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.getOrCreate()"
      ],
      "metadata": {
        "id": "FtwTYOaXE3o5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "49S0SWBOBUl0"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.mllib.util import MLUtils\n",
        "\n",
        "import pandas as pd \n",
        "\n",
        "\n",
        "# Load and parse the data file, converting it to a DataFrame.\n",
        "data = spark.read.csv(\"weatherAUS.csv\", inferSchema= True, header = True) \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.drop(\"Date\",\"Location\",\"Evaporation\",\"Sunshine\",\"Cloud9am\",'Cloud3pm','Temp3pm',\"Temp9am\",\"Temp3am\")"
      ],
      "metadata": {
        "id": "X2Y5MAXMFRFx"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GET RID OF NA VALUES \n",
        "\n",
        "from pyspark.sql.functions import mean\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "for i in data.columns:\n",
        "  count = data.filter(data[i]=='NA').count()\n",
        "\n",
        "numeric_column = ['MinTemp','MaxTemp', 'Rainfall','WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm','Humidity9am','Humidity3pm','Pressure9am','Pressure3pm']\n",
        "\n",
        "# calculate average\n",
        "for i in numeric_column:\n",
        "  average = data.select([mean(i)])\n",
        "\n",
        "# substitute null values with the average\n",
        "updatedmint = data.withColumn(\"MinTemp\",F.when(F.col(\"MinTemp\") == 'NA',12.2).otherwise(F.col(\"MinTemp\")))\n",
        "updatedmaxt = updatedmint.withColumn(\"MaxTemp\",F.when(F.col(\"MaxTemp\") == 'NA',23.2).otherwise(F.col(\"MaxTemp\")))\n",
        "updatedrainf = updatedmaxt.withColumn(\"Rainfall\",F.when(F.col(\"Rainfall\") == 'NA',2.3).otherwise(F.col(\"Rainfall\")))\n",
        "updatedwind = updatedrainf.withColumn(\"WindGustSpeed\",F.when(F.col(\"WindGustSpeed\") == 'NA',40.0).otherwise(F.col(\"WindGustSpeed\")))\n",
        "updatedwinds9 = updatedwind.withColumn(\"WindSpeed9am\",F.when(F.col(\"WindSpeed9am\") == 'NA',14.0).otherwise(F.col(\"WindSpeed9am\")))\n",
        "updatedwinds3 = updatedwinds9.withColumn(\"WindSpeed3pm\",F.when(F.col(\"WindSpeed3pm\") == 'NA',18.6).otherwise(F.col(\"WindSpeed3pm\")))\n",
        "updatedhum9 = updatedwinds3.withColumn(\"Humidity9am\",F.when(F.col(\"Humidity9am\") == 'NA',68.8).otherwise(F.col(\"Humidity9am\")))\n",
        "updatedhum3 = updatedhum9.withColumn(\"Humidity3pm\",F.when(F.col(\"Humidity3pm\") == 'NA',51.5).otherwise(F.col(\"Humidity3pm\")))\n",
        "updatedpres9 = updatedhum3.withColumn(\"Pressure9am\",F.when(F.col(\"Pressure9am\") == 'NA',1017.7).otherwise(F.col(\"Pressure9am\")))\n"
      ],
      "metadata": {
        "id": "XOM5d0xhG-Mj"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSDVly3xFY5G",
        "outputId": "01ba315f-8b08-4504-b5af-0a13c5715e1f"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- MinTemp: string (nullable = true)\n",
            " |-- MaxTemp: string (nullable = true)\n",
            " |-- Rainfall: string (nullable = true)\n",
            " |-- WindGustDir: string (nullable = true)\n",
            " |-- WindGustSpeed: string (nullable = true)\n",
            " |-- WindDir9am: string (nullable = true)\n",
            " |-- WindDir3pm: string (nullable = true)\n",
            " |-- WindSpeed9am: string (nullable = true)\n",
            " |-- WindSpeed3pm: string (nullable = true)\n",
            " |-- Humidity9am: string (nullable = true)\n",
            " |-- Humidity3pm: string (nullable = true)\n",
            " |-- Pressure9am: string (nullable = true)\n",
            " |-- Pressure3pm: string (nullable = true)\n",
            " |-- RainToday: string (nullable = true)\n",
            " |-- RainTomorrow: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYCojMhbGNQJ",
        "outputId": "682d1904-4cd2-43ee-bd6b-2a9c664c0569"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+---------+------------+\n",
            "|MinTemp|MaxTemp|Rainfall|WindGustDir|WindGustSpeed|WindDir9am|WindDir3pm|WindSpeed9am|WindSpeed3pm|Humidity9am|Humidity3pm|Pressure9am|Pressure3pm|RainToday|RainTomorrow|\n",
            "+-------+-------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+---------+------------+\n",
            "|   13.4|   22.9|     0.6|          W|           44|         W|       WNW|          20|          24|         71|         22|     1007.7|     1007.1|       No|          No|\n",
            "|    7.4|   25.1|       0|        WNW|           44|       NNW|       WSW|           4|          22|         44|         25|     1010.6|     1007.8|       No|          No|\n",
            "|   12.9|   25.7|       0|        WSW|           46|         W|       WSW|          19|          26|         38|         30|     1007.6|     1008.7|       No|          No|\n",
            "|    9.2|     28|       0|         NE|           24|        SE|         E|          11|           9|         45|         16|     1017.6|     1012.8|       No|          No|\n",
            "|   17.5|   32.3|       1|          W|           41|       ENE|        NW|           7|          20|         82|         33|     1010.8|       1006|       No|          No|\n",
            "|   14.6|   29.7|     0.2|        WNW|           56|         W|         W|          19|          24|         55|         23|     1009.2|     1005.4|       No|          No|\n",
            "|   14.3|     25|       0|          W|           50|        SW|         W|          20|          24|         49|         19|     1009.6|     1008.2|       No|          No|\n",
            "|    7.7|   26.7|       0|          W|           35|       SSE|         W|           6|          17|         48|         19|     1013.4|     1010.1|       No|          No|\n",
            "|    9.7|   31.9|       0|        NNW|           80|        SE|        NW|           7|          28|         42|          9|     1008.9|     1003.6|       No|         Yes|\n",
            "|   13.1|   30.1|     1.4|          W|           28|         S|       SSE|          15|          11|         58|         27|       1007|     1005.7|      Yes|          No|\n",
            "|   13.4|   30.4|       0|          N|           30|       SSE|       ESE|          17|           6|         48|         22|     1011.8|     1008.7|       No|         Yes|\n",
            "|   15.9|   21.7|     2.2|        NNE|           31|        NE|       ENE|          15|          13|         89|         91|     1010.5|     1004.2|      Yes|         Yes|\n",
            "|   15.9|   18.6|    15.6|          W|           61|       NNW|       NNW|          28|          28|         76|         93|      994.3|        993|      Yes|         Yes|\n",
            "|   12.6|     21|     3.6|         SW|           44|         W|       SSW|          24|          20|         65|         43|     1001.2|     1001.8|      Yes|          No|\n",
            "|    8.4|   24.6|       0|         NA|           NA|         S|       WNW|           4|          30|         57|         32|     1009.7|     1008.7|       No|          NA|\n",
            "|    9.8|   27.7|      NA|        WNW|           50|        NA|       WNW|          NA|          22|         50|         28|     1013.4|     1010.3|       NA|          No|\n",
            "|   14.1|   20.9|       0|        ENE|           22|       SSW|         E|          11|           9|         69|         82|     1012.2|     1010.4|       No|         Yes|\n",
            "|   13.5|   22.9|    16.8|          W|           63|         N|       WNW|           6|          20|         80|         65|     1005.8|     1002.2|      Yes|         Yes|\n",
            "|   11.2|   22.5|    10.6|        SSE|           43|       WSW|        SW|          24|          17|         47|         32|     1009.4|     1009.7|      Yes|          No|\n",
            "|    9.8|   25.6|       0|        SSE|           26|        SE|       NNW|          17|           6|         45|         26|     1019.2|     1017.1|       No|          No|\n",
            "+-------+-------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+---------+------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.distinct().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_p5Bxu2yGjx3",
        "outputId": "235ce963-daff-43a3-80a0-410842ca62b4"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+---------+------------+\n",
            "|MinTemp|MaxTemp|Rainfall|WindGustDir|WindGustSpeed|WindDir9am|WindDir3pm|WindSpeed9am|WindSpeed3pm|Humidity9am|Humidity3pm|Pressure9am|Pressure3pm|RainToday|RainTomorrow|\n",
            "+-------+-------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+---------+------------+\n",
            "|    4.7|   12.2|       0|        NNW|           24|       ESE|         N|           2|          13|         99|         75|     1015.5|     1012.7|       No|         Yes|\n",
            "|    1.6|   17.2|       0|          S|           20|       ESE|         S|           6|           7|         68|         44|     1022.5|     1019.1|       No|          No|\n",
            "|   10.6|   24.7|       0|         NE|           33|        NA|       ENE|           0|          20|         75|         40|     1017.9|     1013.3|       No|         Yes|\n",
            "|      3|   15.6|       0|        WSW|           43|       WNW|       WSW|           9|          20|         77|         47|     1012.5|     1014.8|       No|          No|\n",
            "|    5.2|   16.3|       0|        ESE|           20|       ESE|       ESE|           9|           9|         74|         73|     1017.6|     1013.3|       No|         Yes|\n",
            "|   16.1|   26.6|     0.6|         NW|           50|       ESE|         S|           9|          11|         70|         90|       1015|     1013.3|       No|         Yes|\n",
            "|    3.5|   16.3|       0|        ESE|           11|       SSE|         E|           4|           2|        100|         56|     1030.1|     1025.9|       No|          No|\n",
            "|   14.8|   32.7|       0|        NNE|           28|       ENE|       WNW|           9|           9|         52|         27|     1021.4|     1018.1|       No|          No|\n",
            "|   -1.5|   14.6|       0|        SSE|           24|         S|         S|           6|          11|         76|         42|       1035|     1032.3|       No|          No|\n",
            "|   17.5|   30.2|    13.4|        ENE|           37|       ESE|         S|           7|          13|         80|         48|       1011|     1007.2|      Yes|          No|\n",
            "|   10.8|   30.7|       0|        NNW|           50|       SSE|       NNW|           6|          15|         61|         30|     1022.7|     1017.7|       No|          No|\n",
            "|   11.8|   26.5|       0|          W|           31|         E|        NW|           2|          17|         67|         31|     1020.1|     1017.1|       No|          No|\n",
            "|    3.8|   15.1|       0|        NNE|           31|        SE|       NNW|           9|          19|         99|         58|     1016.4|     1011.6|       No|         Yes|\n",
            "|    0.7|   17.5|     0.2|          W|           41|        NE|       WSW|           6|          26|         80|         50|     1026.6|     1024.4|       No|          No|\n",
            "|    0.4|   12.7|       0|         SE|           15|        NA|        SE|           0|           7|         85|         50|     1037.5|     1036.1|       No|          No|\n",
            "|    9.1|   16.2|    16.6|          N|           44|         N|         N|          22|          19|         82|         52|     1009.3|     1007.9|      Yes|          No|\n",
            "|   17.1|   35.4|       0|          E|           30|       ESE|       SSE|           9|          13|         60|         26|     1016.1|     1012.9|       No|          No|\n",
            "|    1.1|   14.1|     0.2|        WSW|           28|        SW|         W|           4|          15|        100|         49|     1018.8|     1017.2|       No|          No|\n",
            "|   13.2|   25.8|       0|         NE|           30|        SW|         N|          15|          15|         72|         61|     1027.5|     1024.7|       No|          No|\n",
            "|     NA|     24|      NA|        ENE|           24|        NA|         E|          NA|          15|         NA|         64|         NA|     1024.5|       NA|          No|\n",
            "+-------+-------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+---------+------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tbh idk whats going on, so im just gonna drop more columns....\n",
        "data = data.drop(\"MinTemp\",\"MaxTemp\",\"WindGustDir\",\"WindGustSpeed\",\"WindDir9am\",\"WindDir3pm\",\"WindSpeed9am\",\"WindSpeed3pm\",\"Humidity9am\",\"Humidity3pm\",\"Pressure9am\",\"Pressure3pm\")\n",
        "data.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpoxc_OkJnlg",
        "outputId": "a8a67221-b952-4ffa-b651-c689e2641b05"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---------+------------+\n",
            "|Rainfall|RainToday|RainTomorrow|\n",
            "+--------+---------+------------+\n",
            "|     0.6|       No|          No|\n",
            "|       0|       No|          No|\n",
            "|       0|       No|          No|\n",
            "|       0|       No|          No|\n",
            "|       1|       No|          No|\n",
            "|     0.2|       No|          No|\n",
            "|       0|       No|          No|\n",
            "|       0|       No|          No|\n",
            "|       0|       No|         Yes|\n",
            "|     1.4|      Yes|          No|\n",
            "|       0|       No|         Yes|\n",
            "|     2.2|      Yes|         Yes|\n",
            "|    15.6|      Yes|         Yes|\n",
            "|     3.6|      Yes|          No|\n",
            "|       0|       No|          NA|\n",
            "|      NA|       NA|          No|\n",
            "|       0|       No|         Yes|\n",
            "|    16.8|      Yes|         Yes|\n",
            "|    10.6|      Yes|          No|\n",
            "|       0|       No|          No|\n",
            "+--------+---------+------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Index labels, adding metadata to the label column.\n",
        "# Fit on whole dataset to include all labels in index.\n",
        "labelIndexer = StringIndexer(inputCols=[\"RainTomorrow\",\"RainToday\",\"Rainfall\"], \n",
        "                             outputCols=[\"tomorrow_index\",\"today_index\",\"rain_index\"]).fit(data).transform(data)"
      ],
      "metadata": {
        "id": "hEOay1STDcpy"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rain tomorrow index: yes = 1.0, no = 0.0, NA = 2.0\n",
        "\n",
        "labelIndexer.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6dH5InmLbPq",
        "outputId": "3946ecb7-4f8f-455b-afcf-d76ae84d98f8"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---------+------------+--------------+-----------+----------+\n",
            "|Rainfall|RainToday|RainTomorrow|tomorrow_index|today_index|rain_index|\n",
            "+--------+---------+------------+--------------+-----------+----------+\n",
            "|     0.6|       No|          No|           0.0|        0.0|       4.0|\n",
            "|       0|       No|          No|           0.0|        0.0|       0.0|\n",
            "|       0|       No|          No|           0.0|        0.0|       0.0|\n",
            "|       0|       No|          No|           0.0|        0.0|       0.0|\n",
            "|       1|       No|          No|           0.0|        0.0|       6.0|\n",
            "|     0.2|       No|          No|           0.0|        0.0|       1.0|\n",
            "|       0|       No|          No|           0.0|        0.0|       0.0|\n",
            "|       0|       No|          No|           0.0|        0.0|       0.0|\n",
            "|       0|       No|         Yes|           1.0|        0.0|       0.0|\n",
            "|     1.4|      Yes|          No|           0.0|        1.0|       8.0|\n",
            "|       0|       No|         Yes|           1.0|        0.0|       0.0|\n",
            "|     2.2|      Yes|         Yes|           1.0|        1.0|      12.0|\n",
            "|    15.6|      Yes|         Yes|           1.0|        1.0|      81.0|\n",
            "|     3.6|      Yes|          No|           0.0|        1.0|      20.0|\n",
            "|       0|       No|          NA|           2.0|        0.0|       0.0|\n",
            "|      NA|       NA|          No|           0.0|        2.0|       3.0|\n",
            "|       0|       No|         Yes|           1.0|        0.0|       0.0|\n",
            "|    16.8|      Yes|         Yes|           1.0|        1.0|      83.0|\n",
            "|    10.6|      Yes|          No|           0.0|        1.0|      57.0|\n",
            "|       0|       No|          No|           0.0|        0.0|       0.0|\n",
            "+--------+---------+------------+--------------+-----------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import OneHotEncoder\n",
        "\n",
        "encoder = OneHotEncoder(inputCol=\"tomorrow_index\",\n",
        "                        outputCol=\"tomorrow_onehot\", dropLast=False)\n",
        "models = encoder.fit(labelIndexer)\n",
        "encoded = models.transform(labelIndexer)\n"
      ],
      "metadata": {
        "id": "Wh68Dn1GOUYr"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded.show()\n",
        "\n",
        "# TO UNDERSTAND: \n",
        "# tomorrow_onehot = (3,       (rain? yes=1,no=0,NA=[]),      1.0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fr97FEwOSc5r",
        "outputId": "67782e32-89ac-41aa-e781-fb1072ac3d9c"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---------+------------+--------------+-----------+----------+---------------+\n",
            "|Rainfall|RainToday|RainTomorrow|tomorrow_index|today_index|rain_index|tomorrow_onehot|\n",
            "+--------+---------+------------+--------------+-----------+----------+---------------+\n",
            "|     0.6|       No|          No|           0.0|        0.0|       4.0|  (3,[0],[1.0])|\n",
            "|       0|       No|          No|           0.0|        0.0|       0.0|  (3,[0],[1.0])|\n",
            "|       0|       No|          No|           0.0|        0.0|       0.0|  (3,[0],[1.0])|\n",
            "|       0|       No|          No|           0.0|        0.0|       0.0|  (3,[0],[1.0])|\n",
            "|       1|       No|          No|           0.0|        0.0|       6.0|  (3,[0],[1.0])|\n",
            "|     0.2|       No|          No|           0.0|        0.0|       1.0|  (3,[0],[1.0])|\n",
            "|       0|       No|          No|           0.0|        0.0|       0.0|  (3,[0],[1.0])|\n",
            "|       0|       No|          No|           0.0|        0.0|       0.0|  (3,[0],[1.0])|\n",
            "|       0|       No|         Yes|           1.0|        0.0|       0.0|  (3,[1],[1.0])|\n",
            "|     1.4|      Yes|          No|           0.0|        1.0|       8.0|  (3,[0],[1.0])|\n",
            "|       0|       No|         Yes|           1.0|        0.0|       0.0|  (3,[1],[1.0])|\n",
            "|     2.2|      Yes|         Yes|           1.0|        1.0|      12.0|  (3,[1],[1.0])|\n",
            "|    15.6|      Yes|         Yes|           1.0|        1.0|      81.0|  (3,[1],[1.0])|\n",
            "|     3.6|      Yes|          No|           0.0|        1.0|      20.0|  (3,[0],[1.0])|\n",
            "|       0|       No|          NA|           2.0|        0.0|       0.0|  (3,[2],[1.0])|\n",
            "|      NA|       NA|          No|           0.0|        2.0|       3.0|  (3,[0],[1.0])|\n",
            "|       0|       No|         Yes|           1.0|        0.0|       0.0|  (3,[1],[1.0])|\n",
            "|    16.8|      Yes|         Yes|           1.0|        1.0|      83.0|  (3,[1],[1.0])|\n",
            "|    10.6|      Yes|          No|           0.0|        1.0|      57.0|  (3,[0],[1.0])|\n",
            "|       0|       No|          No|           0.0|        0.0|       0.0|  (3,[0],[1.0])|\n",
            "+--------+---------+------------+--------------+-----------+----------+---------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark.sql.functions as f\n",
        "# Split the data 80/20 train/test, using a seed of 12345\n",
        "(trainingData, testData) = data.randomSplit([0.8, 0.2],seed = 12345)\n",
        "print(f\"Train set length: {trainingData.count()} records\")\n",
        "print(f\"Train set length: {testData.count()} records\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KILVj2vlMKHN",
        "outputId": "d30106ef-0aaf-46f6-e59d-ef5ec7f10ddb"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set length: 116263 records\n",
            "Train set length: 29197 records\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6fPqN1CaWUh",
        "outputId": "b4ccdff2-b2f8-4484-d6ce-be1eb71e7dde"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[summary: string, Rainfall: string, RainToday: string, RainTomorrow: string, tomorrow_index: string, today_index: string, rain_index: string]"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# making sure target variable didnt get messed up....\n",
        "data.groupBy(\"RainTomorrow\").count().show()\n",
        "encoded.groupBy(\"RainTomorrow\").count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoqJEtowbkHP",
        "outputId": "79c51d05-10cd-46ea-ab17-c542e8f70763"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+------+\n",
            "|RainTomorrow| count|\n",
            "+------------+------+\n",
            "|          NA|  3267|\n",
            "|          No|110316|\n",
            "|         Yes| 31877|\n",
            "+------------+------+\n",
            "\n",
            "+------------+------+\n",
            "|RainTomorrow| count|\n",
            "+------------+------+\n",
            "|          NA|  3267|\n",
            "|          No|110316|\n",
            "|         Yes| 31877|\n",
            "+------------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlOtovcUcDNY",
        "outputId": "bd23f43b-bd4e-4fba-cc9f-f3e1d2bc75ad"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+---------+------------+\n",
            "|summary|          Rainfall|RainToday|RainTomorrow|\n",
            "+-------+------------------+---------+------------+\n",
            "|  count|            145460|   145460|      145460|\n",
            "|   mean|2.3609181499168272|     null|        null|\n",
            "| stddev| 8.478059737726392|     null|        null|\n",
            "|    min|                 0|       NA|          NA|\n",
            "|    max|                NA|      Yes|         Yes|\n",
            "+-------+------------------+---------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LET ME USE A VECTOR ASSEMBLY INSTEADDDD\n",
        "data.columns\n",
        "\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "assembler = VectorAssembler(inputCols=[\"tomorrow_index\",\"today_index\",\"rain_index\"],\n",
        "                            outputCol= \"features\")"
      ],
      "metadata": {
        "id": "58b0rrVDcerp"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assembler"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUuZW9xkcevX",
        "outputId": "cfe1fe71-9f1c-421d-a570-ca1075e0d959"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function JavaWrapper.__del__ at 0x7fb550df0200>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pyspark/ml/wrapper.py\", line 39, in __del__\n",
            "    if SparkContext._active_spark_context and self._java_obj is not None:\n",
            "AttributeError: 'VectorAssembler' object has no attribute '_java_obj'\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VectorAssembler_cb5cf186d465"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = assembler.transform(labelIndexer)\n",
        "\n",
        "output.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9wEnWthce30",
        "outputId": "23cf1358-bb78-44ed-b11b-9eb421f604fa"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---------+------------+--------------+-----------+----------+--------------+\n",
            "|Rainfall|RainToday|RainTomorrow|tomorrow_index|today_index|rain_index|      features|\n",
            "+--------+---------+------------+--------------+-----------+----------+--------------+\n",
            "|     0.6|       No|          No|           0.0|        0.0|       4.0| [0.0,0.0,4.0]|\n",
            "|       0|       No|          No|           0.0|        0.0|       0.0|     (3,[],[])|\n",
            "|       0|       No|          No|           0.0|        0.0|       0.0|     (3,[],[])|\n",
            "|       0|       No|          No|           0.0|        0.0|       0.0|     (3,[],[])|\n",
            "|       1|       No|          No|           0.0|        0.0|       6.0| [0.0,0.0,6.0]|\n",
            "|     0.2|       No|          No|           0.0|        0.0|       1.0| [0.0,0.0,1.0]|\n",
            "|       0|       No|          No|           0.0|        0.0|       0.0|     (3,[],[])|\n",
            "|       0|       No|          No|           0.0|        0.0|       0.0|     (3,[],[])|\n",
            "|       0|       No|         Yes|           1.0|        0.0|       0.0| [1.0,0.0,0.0]|\n",
            "|     1.4|      Yes|          No|           0.0|        1.0|       8.0| [0.0,1.0,8.0]|\n",
            "|       0|       No|         Yes|           1.0|        0.0|       0.0| [1.0,0.0,0.0]|\n",
            "|     2.2|      Yes|         Yes|           1.0|        1.0|      12.0|[1.0,1.0,12.0]|\n",
            "|    15.6|      Yes|         Yes|           1.0|        1.0|      81.0|[1.0,1.0,81.0]|\n",
            "|     3.6|      Yes|          No|           0.0|        1.0|      20.0|[0.0,1.0,20.0]|\n",
            "|       0|       No|          NA|           2.0|        0.0|       0.0| [2.0,0.0,0.0]|\n",
            "|      NA|       NA|          No|           0.0|        2.0|       3.0| [0.0,2.0,3.0]|\n",
            "|       0|       No|         Yes|           1.0|        0.0|       0.0| [1.0,0.0,0.0]|\n",
            "|    16.8|      Yes|         Yes|           1.0|        1.0|      83.0|[1.0,1.0,83.0]|\n",
            "|    10.6|      Yes|          No|           0.0|        1.0|      57.0|[0.0,1.0,57.0]|\n",
            "|       0|       No|          No|           0.0|        0.0|       0.0|     (3,[],[])|\n",
            "+--------+---------+------------+--------------+-----------+----------+--------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output.select(\"features\", \"tomorrow_index\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KZFBvi6drcs",
        "outputId": "cd237be8-12a1-4a43-df7e-67da2ff59c66"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+--------------+\n",
            "|      features|tomorrow_index|\n",
            "+--------------+--------------+\n",
            "| [0.0,0.0,4.0]|           0.0|\n",
            "|     (3,[],[])|           0.0|\n",
            "|     (3,[],[])|           0.0|\n",
            "|     (3,[],[])|           0.0|\n",
            "| [0.0,0.0,6.0]|           0.0|\n",
            "| [0.0,0.0,1.0]|           0.0|\n",
            "|     (3,[],[])|           0.0|\n",
            "|     (3,[],[])|           0.0|\n",
            "| [1.0,0.0,0.0]|           1.0|\n",
            "| [0.0,1.0,8.0]|           0.0|\n",
            "| [1.0,0.0,0.0]|           1.0|\n",
            "|[1.0,1.0,12.0]|           1.0|\n",
            "|[1.0,1.0,81.0]|           1.0|\n",
            "|[0.0,1.0,20.0]|           0.0|\n",
            "| [2.0,0.0,0.0]|           2.0|\n",
            "| [0.0,2.0,3.0]|           0.0|\n",
            "| [1.0,0.0,0.0]|           1.0|\n",
            "|[1.0,1.0,83.0]|           1.0|\n",
            "|[0.0,1.0,57.0]|           0.0|\n",
            "|     (3,[],[])|           0.0|\n",
            "+--------------+--------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_df = output.select(\"tomorrow_index\",\"today_index\",\"rain_index\",\"features\")\n",
        "model_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UP0B3RZ1D1d7",
        "outputId": "b458714f-f56e-42ec-b994-8da47186312a"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+-----------+----------+--------------+\n",
            "|tomorrow_index|today_index|rain_index|      features|\n",
            "+--------------+-----------+----------+--------------+\n",
            "|           0.0|        0.0|       4.0| [0.0,0.0,4.0]|\n",
            "|           0.0|        0.0|       0.0|     (3,[],[])|\n",
            "|           0.0|        0.0|       0.0|     (3,[],[])|\n",
            "|           0.0|        0.0|       0.0|     (3,[],[])|\n",
            "|           0.0|        0.0|       6.0| [0.0,0.0,6.0]|\n",
            "|           0.0|        0.0|       1.0| [0.0,0.0,1.0]|\n",
            "|           0.0|        0.0|       0.0|     (3,[],[])|\n",
            "|           0.0|        0.0|       0.0|     (3,[],[])|\n",
            "|           1.0|        0.0|       0.0| [1.0,0.0,0.0]|\n",
            "|           0.0|        1.0|       8.0| [0.0,1.0,8.0]|\n",
            "|           1.0|        0.0|       0.0| [1.0,0.0,0.0]|\n",
            "|           1.0|        1.0|      12.0|[1.0,1.0,12.0]|\n",
            "|           1.0|        1.0|      81.0|[1.0,1.0,81.0]|\n",
            "|           0.0|        1.0|      20.0|[0.0,1.0,20.0]|\n",
            "|           2.0|        0.0|       0.0| [2.0,0.0,0.0]|\n",
            "|           0.0|        2.0|       3.0| [0.0,2.0,3.0]|\n",
            "|           1.0|        0.0|       0.0| [1.0,0.0,0.0]|\n",
            "|           1.0|        1.0|      83.0|[1.0,1.0,83.0]|\n",
            "|           0.0|        1.0|      57.0|[0.0,1.0,57.0]|\n",
            "|           0.0|        0.0|       0.0|     (3,[],[])|\n",
            "+--------------+-----------+----------+--------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_df, test_df = model_df.randomSplit([0.8,0.2],seed = 12345)"
      ],
      "metadata": {
        "id": "SK3gvmElEVog"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_df.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXc8HD1fEoEO",
        "outputId": "84787da8-0f34-4b23-d0a8-01e2d85aab27"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "116263"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pd6vDQ8lEpAe",
        "outputId": "763595eb-b595-49a4-e5f9-2c88ef44ac95"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29197"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
      ],
      "metadata": {
        "id": "ydH8o2zUEpG-"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.mllib.tree import DecisionTree\n",
        "model = DecisionTree.trainClassifier(training_df, numClasses=2, categoricalFeaturesInfo={},\n",
        "                                     impurity='gini', maxDepth=5, maxBins=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "vYIo9eEQL6zR",
        "outputId": "fcfa75ee-cf7b-4203-b138-6aa93d28d7c7"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-123-dd56a0df1f45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDecisionTree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m model = DecisionTree.trainClassifier(training_df, numClasses=2, categoricalFeaturesInfo={},\n\u001b[0;32m----> 3\u001b[0;31m                                      impurity='gini', maxDepth=5, maxBins=32)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/mllib/tree.py\u001b[0m in \u001b[0;36mtrainClassifier\u001b[0;34m(cls, data, numClasses, categoricalFeaturesInfo, impurity, maxDepth, maxBins, minInstancesPerNode, minInfoGain)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \"\"\"\n\u001b[1;32m    227\u001b[0m         return cls._train(data, \"classification\", numClasses, categoricalFeaturesInfo,\n\u001b[0;32m--> 228\u001b[0;31m                           impurity, maxDepth, maxBins, minInstancesPerNode, minInfoGain)\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/mllib/tree.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(cls, data, type, numClasses, features, impurity, maxDepth, maxBins, minInstancesPerNode, minInfoGain)\u001b[0m\n\u001b[1;32m    146\u001b[0m                minInstancesPerNode=1, minInfoGain=0.0):\n\u001b[1;32m    147\u001b[0m         \u001b[0mfirst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLabeledPoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"the data should be RDD of LabeledPoint\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         model = callMLlibFunc(\"trainDecisionTreeModel\", data, type, numClasses, features,\n\u001b[1;32m    150\u001b[0m                               impurity, maxDepth, maxBins, minInstancesPerNode, minInfoGain)\n",
            "\u001b[0;31mAssertionError\u001b[0m: the data should be RDD of LabeledPoint"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKjKIjpYMYiD",
        "outputId": "ac521448-0c3f-497b-d157-2a7a9f5b1114"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[DataFrame[Rainfall: string, RainToday: string, RainTomorrow: string, tomorrow_index: double, today_index: double, rain_index: double, features: vector]]"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import Pipeline\n",
        "\n",
        "pipeline = Pipeline().setStages(stages)\n",
        "model = pipeline.fit(training_df)\n",
        "iw_df = model.transform(test_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "4WuSwWNrLcUc",
        "outputId": "f3ad610d-093d-475b-c532-946fb4afd8fb"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-113-b3329ee7197a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetStages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0miw_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             raise TypeError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/ml/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEstimator\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransformer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 raise TypeError(\n\u001b[0;32m--> 102\u001b[0;31m                     \"Cannot recognize a pipeline stage of type %s.\" % type(stage))\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0mindexOfLastEstimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Cannot recognize a pipeline stage of type <class 'pyspark.sql.dataframe.DataFrame'>."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_classifier = DecisionTreeClassifier(labelCol=\"tomorrow_index\").fit(training_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "AJwcsVQuEpLv",
        "outputId": "fa2ca2ad-8a42-4dad-8e30-854ae9821e94"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IllegalArgumentException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-106-1426206b9bc2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_classifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabelCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"tomorrow_index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             raise TypeError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \"\"\"\n\u001b[1;32m    331\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1322\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIllegalArgumentException\u001b[0m: requirement failed: DecisionTree requires maxBins (= 32) to be at least as large as the number of values in each categorical feature, but categorical feature 2 has 682 values. Consider removing this and other categorical features with a large number of values, or add more training examples."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_predictions = df_classifier.transform(test_df)"
      ],
      "metadata": {
        "id": "oChzsGuyEpOh"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HMMMMM....why did it make everything the same....\n",
        "df_predictions.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1RGhWXKFwBO",
        "outputId": "711f280f-0f56-419e-cf68-dab5017a5639"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------+-----------------+-------------+----------+\n",
            "|features|tomorrow_index|    rawPrediction|  probability|prediction|\n",
            "+--------+--------------+-----------------+-------------+----------+\n",
            "|   [0.0]|           0.0|[88195.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
            "|   [0.0]|           0.0|[88195.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
            "|   [0.0]|           0.0|[88195.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
            "|   [0.0]|           0.0|[88195.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
            "|   [0.0]|           0.0|[88195.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
            "|   [0.0]|           0.0|[88195.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
            "|   [0.0]|           0.0|[88195.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
            "|   [0.0]|           0.0|[88195.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
            "|   [0.0]|           0.0|[88195.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
            "|   [0.0]|           0.0|[88195.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
            "|   [0.0]|           0.0|[88195.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
            "|   [0.0]|           0.0|[88195.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
            "|   [0.0]|           0.0|[88195.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
            "|   [0.0]|           0.0|[88195.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
            "|   [0.0]|           0.0|[88195.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
            "|   [0.0]|           0.0|[88195.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
            "|   [0.0]|           0.0|[88195.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
            "|   [0.0]|           0.0|[88195.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
            "|   [0.0]|           0.0|[88195.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
            "|   [0.0]|           0.0|[88195.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
            "+--------+--------------+-----------------+-------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_accuracy = MulticlassClassificationEvaluator(labelCol=\"tomorrow_index\",\n",
        "                                                metricName=\"accuracy\").evaluate(df_predictions)"
      ],
      "metadata": {
        "id": "alfHZ7iRY1Gg"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4InVUL38Ge-I",
        "outputId": "15917549-0a86-4c13-fe3c-a9e3002384d1"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_precision = MulticlassClassificationEvaluator(labelCol = \"tomorrow_index\",\n",
        "                                                 metricName=\"weightedPrecision\").evaluate(df_predictions)"
      ],
      "metadata": {
        "id": "FJzq7XtzHBHs"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_precision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otK3V4WRHTkl",
        "outputId": "bf91f768-425c-40c5-88bc-404ff8e0b787"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_classifier.featureImportances"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5Q2RHdEHYXr",
        "outputId": "7a0ec995-812d-4d66-a891-cd0c697e1c22"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SparseVector(1, {0: 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_auc = MulticlassClassificationEvaluator(labelCol = \"tomorrow_index\").evaluate(df_predictions)"
      ],
      "metadata": {
        "id": "SfJi-D5aHvo7"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_auc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvXNs2LZICyV",
        "outputId": "bd8e7742-8e0b-4cbd-d539-f14024703908"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    }
  ]
}